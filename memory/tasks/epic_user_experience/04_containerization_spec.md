# Story Spec: Full Containerization

**User Story:** As an advanced developer, I want to use Docker to run the MCP server in an isolated environment, ensuring consistency and simplifying deployment.

---

### Feature 4.1: Docker-based Deployment

**Description:** Provide a verified, step-by-step guide and the necessary configuration to run the MCP server as a Docker container that can successfully connect to external services (like Neo4j) running on the host machine.

*   **Acceptance Criteria:**
    *   A developer can follow a guide to successfully build and run the MCP server in a Docker container.
    *   The containerized MCP server successfully connects to the Neo4j database running on the host machine.
    *   The `validate_setup.py` script (from Story #3) can be executed *against* the containerized server and pass all checks.
    *   The root `README.md` is updated with instructions for the Docker-based setup, including the one-time data ingestion command.
    *   The `docker run` command for data ingestion streams the server's `stdout` to the user's terminal in real-time.
    *   Artifacts generated by the ingestion script (e.g., `langgraph_doc_rag.json`) are saved to the host machine.

*   **Implementation Plan:**
    - [ ] `[P0 - Must Have]` **Task: Create a Connection Test Script:**
        - [ ] Create a new, temporary Python script (`mcp-crawl4ai-rag/test_docker_neo4j.py`).
        - [ ] This script will *only* contain the logic to connect to Neo4j using credentials from the `.env` file.
        - [ ] It should print a "SUCCESS" or "FAILURE" message. This allows for a fast, isolated test of the core problem.
    - [ ] `[P0 - Must Have]` **Task: Verify the Docker-to-Host Connection:**
        - [ ] Manually configure the `mcp-crawl4ai-rag/.env` file, setting `NEO4J_URI=bolt://host.docker.internal:7687`.
        - [ ] Build the Docker image: `docker build -t mcp/test-neo4j .`
        - [ ] Run the container, overriding the entrypoint to execute our test script: `docker run --env-file .env mcp/test-neo4j uv run python test_docker_neo4j.py`.
        - [ ] Confirm the script prints "SUCCESS". This validates that the primary blocker is resolved.
    - [ ] `[P0 - Must Have]` **Task: Document the Full Process in README:**
        - [ ] Once verified, update the root `README.md` with the full, detailed instructions for the Docker-based setup.
        - [ ] **Sub-Task:** Document the one-time data ingestion command, including the memory flag and volume mounts for both the `.env` file and the reports directory.
            ```bash
            # Command to run the one-time data ingestion in a temporary container
            docker run --rm --memory "512m" \
              -v "$(pwd)/mcp-crawl4ai-rag/.env:/app/.env" \
              -v "$(pwd)/mcp-crawl4ai-rag/reports:/app/reports" \
              mcp-crawl4ai-rag \
              python -u run_one_time_ingestion.py
            ```
        - [ ] **Sub-Task:** Document the server launch command.
            ```bash
            # Command to build the image and run the server
            docker build -t mcp/crawl4ai-rag .
            docker run --env-file .env -p 8051:8051 mcp/crawl4ai-rag
            ```
        - [ ] **Sub-Task:** Document OS-specific `NEO4J_URI` configuration.
        - [ ] **Sub-Task:** Document how to run the `validate_setup.py` script against the running container.
    - [ ] `[P0 - Must Have]` **Task: Clean Up:**
        - [ ] Remove the temporary `test_docker_neo4j.py` script.
    - [ ] Create a pull request for review.

### Future Improvements
- [ ] `[P1 - Nice to Have]` **Task: Automate container cleanup** to prevent orphaned containers from causing conflicts on restart.

---

### Key Findings & Implementation Notes

*   **Memory Allocation is Critical:** The primary blocker for containerization was discovered to be memory. The application requires at least **512MB of memory** to start reliably. The `docker run` command *must* include the `--memory "512m"` flag.
*   **Detailed Investigation:** The full analysis of this issue, including debugging steps and logs, is documented in [04_containerization_findings.md](./04_containerization_findings.md).
